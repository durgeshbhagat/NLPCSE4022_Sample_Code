{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "360804cb",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization using NLTK\n",
    "## Index\n",
    "### 1. Download NTLK package\n",
    "### 2. Stemming  - PorterStemmer \n",
    "### 3. Lemmatization -  WordNetLemmatizer\n",
    "### 4. Stemming vs Lemmtization comparision for different words\n",
    "       - Marraige, University, Better\n",
    "       - verb with ing form \n",
    "       - adjective\n",
    "#### 5. Stemming vs Lemmatization on a sentence/corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a42bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\JaiBrahma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb52523",
   "metadata": {},
   "source": [
    "## 2. Stemming using NLTK Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a5d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f63acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word= Marriage, stemming_form=marriag\n",
      "word= University, stemming_form=univers\n",
      "word= better, stemming_form=better\n"
     ]
    }
   ],
   "source": [
    "porter_stemmer  = PorterStemmer()\n",
    "word = 'Marriage'\n",
    "print(\"word= {}, stemming_form={}\".format(word, porter_stemmer.stem(word)))\n",
    "word = 'University'\n",
    "print(\"word= {}, stemming_form={}\".format(word, porter_stemmer.stem(word)))\n",
    "word = 'better'\n",
    "print(\"word= {}, stemming_form={}\".format(word, porter_stemmer.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15271572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming for studies is studi\n",
      "Stemming for beautiful is beauti\n",
      "Stemming for awful is aw\n",
      "Stemming for tastier is tastier\n",
      "Stemming for studying is studi\n",
      "Stemming for cries is cri\n",
      "Stemming for cry is cri\n",
      "Stemming for bitter is bitter\n",
      "Stemming for studying is studi\n",
      "Stemming for walking is walk\n",
      "Stemming for enjoying is enjoy\n"
     ]
    }
   ],
   "source": [
    "porter_stemmer  = PorterStemmer()\n",
    "text = \"studies beautiful awful tastier studying cries cry bitter studying walking enjoying\"\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "for w in tokenization:\n",
    "    print(\"Stemming for {} is {}\".format(w,porter_stemmer.stem(w)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77763b82",
   "metadata": {},
   "source": [
    "## 3. Lemmatization using NLTK WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a506100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import these modules\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9e9d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks =>  rock\n",
      "studying => study\n",
      "walking => walk\n",
      "better => better\n",
      "better => good\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "print(\"rocks => \", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"studying =>\", lemmatizer.lemmatize(\"studying\", pos=\"v\"))\n",
    "print(\"walking =>\", lemmatizer.lemmatize(\"walking\", pos=\"v\"))\n",
    "print(\"better =>\", lemmatizer.lemmatize(\"better\")) \n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better =>\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b750e3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method lemmatize in module nltk.stem.wordnet:\n",
      "\n",
      "lemmatize(word: str, pos: str = 'n') -> str method of nltk.stem.wordnet.WordNetLemmatizer instance\n",
      "    Lemmatize `word` using WordNet's built-in morphy function.\n",
      "    Returns the input word unchanged if it cannot be found in WordNet.\n",
      "    \n",
      "    :param word: The input word to lemmatize.\n",
      "    :type word: str\n",
      "    :param pos: The Part Of Speech tag. Valid options are `\"n\"` for nouns,\n",
      "        `\"v\"` for verbs, `\"a\"` for adjectives, `\"r\"` for adverbs and `\"s\"`\n",
      "        for satellite adjectives.\n",
      "    :param pos: str\n",
      "    :return: The lemma of `word`, for the given `pos`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lemmatizer.lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ecd50",
   "metadata": {},
   "source": [
    "#### lammatizer.lemmatize takes two arguements\n",
    "    - word and its POS (parts-of-speech)\n",
    "    - if no POS is given, it will consider word as Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f867b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going => going\n"
     ]
    }
   ],
   "source": [
    "word = \"going\"\n",
    "print(\"{} => {}\".format(word, lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fee7d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going => go\n",
      "went => go\n",
      "gone => go\n"
     ]
    }
   ],
   "source": [
    "word = \"going\"\n",
    "print(\"{} => {}\".format(word, lemmatizer.lemmatize(word, pos=\"v\")))\n",
    "word = \"went\"\n",
    "print(\"{} => {}\".format(word, lemmatizer.lemmatize(word, pos=\"v\")))\n",
    "word = \"gone\"\n",
    "print(\"{} => {}\".format(word, lemmatizer.lemmatize(word, pos=\"v\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a3fbd",
   "metadata": {},
   "source": [
    "### 4. Stemming vs Lemmtization comparision for different words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d823a3",
   "metadata": {},
   "source": [
    "#### 4.1 verb list with -ing forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f6d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word= Marriage, stemming_form=marriag, lemmatized_form=Marriage\n",
      "word= University, stemming_form=univers, lemmatized_form=University\n",
      "word= better, stemming_form=better, lemmatized_form=good\n",
      "word= tastier, stemming_form=tastier, lemmatized_form=tastier\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer  = PorterStemmer()\n",
    "word = 'Marriage'\n",
    "print(\"word= {}, stemming_form={}, lemmatized_form={}\".format(word, porter_stemmer.stem(word), lemmatizer.lemmatize(word, pos =\"n\")))\n",
    "\n",
    "word = 'University'\n",
    "print(\"word= {}, stemming_form={}, lemmatized_form={}\".format(word, porter_stemmer.stem(word), lemmatizer.lemmatize(word, pos =\"n\")))\n",
    "\n",
    "word = 'better'\n",
    "print(\"word= {}, stemming_form={}, lemmatized_form={}\".format(word, porter_stemmer.stem(word), lemmatizer.lemmatize(word, pos =\"a\")))\n",
    "\n",
    "word = 'tastier'\n",
    "print(\"word= {}, stemming_form={}, lemmatized_form={}\".format(word, porter_stemmer.stem(word), lemmatizer.lemmatize(word, pos =\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63fbcfcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word= are, stemming_form=are, lemmatized_form=be\n",
      "word= studying, stemming_form=studi, lemmatized_form=study\n",
      "word= walking, stemming_form=walk, lemmatized_form=walk\n",
      "word= crying, stemming_form=cri, lemmatized_form=cry\n",
      "word= cries, stemming_form=cri, lemmatized_form=cry\n",
      "word= reading, stemming_form=read, lemmatized_form=read\n",
      "word= enjoying, stemming_form=enjoy, lemmatized_form=enjoy\n",
      "word= smoking, stemming_form=smoke, lemmatized_form=smoke\n",
      "word= increasing, stemming_form=increas, lemmatized_form=increase\n",
      "word= kissing, stemming_form=kiss, lemmatized_form=kiss\n",
      "word= changing, stemming_form=chang, lemmatized_form=change\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer  = PorterStemmer()\n",
    "\n",
    "verb_list = \"are studying walking crying cries reading enjoying smoking increasing kissing changing\".split(\" \")\n",
    "for word in verb_list:\n",
    "    print(\"word= {}, stemming_form={}, lemmatized_form={}\".format(word, porter_stemmer.stem(word), lemmatizer.lemmatize(word, pos =\"v\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28160989",
   "metadata": {},
   "source": [
    "#### 4.2 adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "752d11dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word= marriage, stemming_form=marriag, lemmatized_form=marriage\n",
      "word= awful, stemming_form=aw, lemmatized_form=awful\n",
      "word= better, stemming_form=better, lemmatized_form=good\n",
      "word= awesome, stemming_form=awesom, lemmatized_form=awesome\n",
      "word= homeless, stemming_form=homeless, lemmatized_form=homeless\n",
      "word= lucky, stemming_form=lucki, lemmatized_form=lucky\n",
      "word= lonely, stemming_form=lone, lemmatized_form=lonely\n",
      "word= vast, stemming_form=vast, lemmatized_form=vast\n",
      "word= annoyed, stemming_form=annoy, lemmatized_form=annoyed\n"
     ]
    }
   ],
   "source": [
    "adjective_list = \"marriage awful better awesome homeless lucky lonely vast annoyed\".split(' ')\n",
    "for word in adjective_list:\n",
    "    print(\"word= {}, stemming_form={}, lemmatized_form={}\".format(word, porter_stemmer.stem(word), lemmatizer.lemmatize(word, pos =\"a\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443a6de",
   "metadata": {},
   "source": [
    "#### 4.3 adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d6c8f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word= abnormally, stemming_form=abnorm, lemmatized_form=abnormally\n",
      "word= boldly, stemming_form=boldli, lemmatized_form=boldly\n",
      "word= quickly, stemming_form=quickli, lemmatized_form=quickly\n",
      "word= regularly, stemming_form=regularli, lemmatized_form=regularly\n",
      "word= monthly, stemming_form=monthli, lemmatized_form=monthly\n",
      "word= more, stemming_form=more, lemmatized_form=more\n",
      "word= verbally, stemming_form=verbal, lemmatized_form=verbally\n",
      "word= yearly, stemming_form=yearli, lemmatized_form=yearly\n"
     ]
    }
   ],
   "source": [
    "adverb_list= \"abnormally boldly quickly regularly monthly more verbally yearly\".split(' ')\n",
    "for word in adverb_list:\n",
    "    print(\"word= {}, stemming_form={}, lemmatized_form={}\".format(word, porter_stemmer.stem(word), lemmatizer.lemmatize(word, pos =\"r\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46501f3",
   "metadata": {},
   "source": [
    "### 5. Stemmming vs Lemmatization on a sentence/corpus\n",
    " - the indivdual word has to be stemmed or lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e17ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORDNET LEMMATIZER (with appropriate pos tags)\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "# Define function to lemmatize each word with its POS tag\n",
    " \n",
    "# POS_TAGGER_FUNCTION : TYPE 1\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n",
    " \n",
    "\n",
    "\n",
    "#> the cat can be sit with the bat on the striped mat under many fly geese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52c20a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_tagged:: [('the', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('with', 'IN'), ('the', 'DT'), ('bats', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('striped', 'JJ'), ('mat', 'NN'), ('under', 'IN'), ('many', 'JJ'), ('badly', 'RB'), ('flying', 'VBG'), ('geese', 'JJ')]\n",
      "\n",
      "wordnet_tagged ::: [('the', None), ('cat', 'n'), ('is', 'v'), ('sitting', 'v'), ('with', None), ('the', None), ('bats', 'n'), ('on', None), ('the', None), ('striped', 'a'), ('mat', 'n'), ('under', None), ('many', 'a'), ('badly', 'r'), ('flying', 'v'), ('geese', 'a')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'the cat is sitting with the bats on the striped mat under many badly flying geese'\n",
    "\n",
    "word_list = nltk.word_tokenize(sentence)\n",
    "\n",
    "# tokenize the sentence and find the POS tag for each token\n",
    "pos_tagged = nltk.pos_tag(word_list) \n",
    " \n",
    "print('pos_tagged::', pos_tagged, end='\\n\\n')\n",
    "#>[('the', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('with', 'IN'),\n",
    "# ('the', 'DT'), ('bats', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('striped', 'JJ'),\n",
    "# ('mat', 'NN'), ('under', 'IN'), ('many', 'JJ'), ('flying', 'VBG'), ('geese', 'JJ')]\n",
    " \n",
    "# As you may have noticed, the above pos tags are a little confusing.\n",
    " \n",
    "# we use our own pos_tagger function to make things simpler to understand.\n",
    "wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "print('wordnet_tagged :::', wordnet_tagged, end='\\n\\n')\n",
    "#>[('the', None), ('cat', 'n'), ('is', 'v'), ('sitting', 'v'), ('with', None),\n",
    "# ('the', None), ('bats', 'n'), ('on', None), ('the', None), ('striped', 'a'),\n",
    "# ('mat', 'n'), ('under', None), ('many', 'a'), ('flying', 'v'), ('geese', 'a')]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d7874d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word=the, stemmed form => the, lemmatized form=>the\n",
      "word=cat, stemmed form => cat, lemmatized form=> cat\n",
      "word=is, stemmed form => is, lemmatized form=> be\n",
      "word=sitting, stemmed form => sit, lemmatized form=> sit\n",
      "word=with, stemmed form => with, lemmatized form=>with\n",
      "word=the, stemmed form => the, lemmatized form=>the\n",
      "word=bats, stemmed form => bat, lemmatized form=> bat\n",
      "word=on, stemmed form => on, lemmatized form=>on\n",
      "word=the, stemmed form => the, lemmatized form=>the\n",
      "word=striped, stemmed form => stripe, lemmatized form=> striped\n",
      "word=mat, stemmed form => mat, lemmatized form=> mat\n",
      "word=under, stemmed form => under, lemmatized form=>under\n",
      "word=many, stemmed form => mani, lemmatized form=> many\n",
      "word=badly, stemmed form => badli, lemmatized form=> badly\n",
      "word=flying, stemmed form => fli, lemmatized form=> fly\n",
      "word=geese, stemmed form => gees, lemmatized form=> geese\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for  word, tag in wordnet_tagged:\n",
    "    #print(word, tag)\n",
    "    if tag is None:\n",
    "        print(\"word={}, stemmed form => {}, lemmatized form=>{}\".format(word, porter_stemmer.stem(word), word) )\n",
    "    else:\n",
    "        print(\"word={}, stemmed form => {}, lemmatized form=> {}\".format(word, porter_stemmer.stem(word),  lemmatizer.lemmatize(word, pos=tag) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00e107ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence =>  the cat is sitting with the bats on the striped mat under many badly flying geese\n",
      "\n",
      "stemmed_sentence =>  the cat is sit with the bat on the stripe mat under mani badli fli gees\n",
      "\n",
      "lemmatized_sentence =>  the cat be sit with the bat on the striped mat under many badly fly geese\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stemmed_sentence = []\n",
    "lemmatized_sentence = []\n",
    "for  word, tag in wordnet_tagged:\n",
    "    stemmed_sentence.append(porter_stemmer.stem(word))\n",
    "    if tag is None:\n",
    "        lemmatized_sentence.append(word)\n",
    "    else:\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos=tag) )\n",
    "\n",
    "print('Original Sentence => ', ' '.join(word_list), end= '\\n\\n')\n",
    "print('stemmed_sentence => ', ' '.join(stemmed_sentence), end= '\\n\\n')\n",
    "print('lemmatized_sentence => ', ' '.join(lemmatized_sentence), end= '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1c46a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sentence(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "\n",
    "    # tokenize the sentence and find the POS tag for each token\n",
    "    pos_tagged = nltk.pos_tag(word_list) \n",
    "\n",
    "    print('pos_tagged::', pos_tagged, end='\\n\\n')\n",
    "    #>[('the', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('with', 'IN'),\n",
    "    # ('the', 'DT'), ('bats', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('striped', 'JJ'),\n",
    "    # ('mat', 'NN'), ('under', 'IN'), ('many', 'JJ'), ('flying', 'VBG'), ('geese', 'JJ')]\n",
    "\n",
    "    # As you may have noticed, the above pos tags are a little confusing.\n",
    "\n",
    "    # we use our own pos_tagger function to make things simpler to understand.\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "    print('wordnet_tagged :::', wordnet_tagged, end='\\n\\n')\n",
    "    \n",
    "    stemmed_sentence = []\n",
    "    lemmatized_sentence = []\n",
    "    for  word, tag in wordnet_tagged:\n",
    "        stemmed_sentence.append(porter_stemmer.stem(word))\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, pos=tag) )\n",
    "\n",
    "    print('Original Sentence => ', ' '.join(word_list), end= '\\n\\n')\n",
    "    print('stemmed_sentence => ', ' '.join(stemmed_sentence), end= '\\n\\n')\n",
    "    print('lemmatized_sentence => ', ' '.join(lemmatized_sentence), end= '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd833a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering by default as noun :  tastier\n",
      "Considering as adjective: tasty\n"
     ]
    }
   ],
   "source": [
    "word= 'tastier'\n",
    "print('Considering by default as noun : ', lemmatizer.lemmatize(word))\n",
    "print('Considering as adjective:', lemmatizer.lemmatize(word, pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15729b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_tagged:: [('The', 'DT'), ('panner', 'NN'), ('is', 'VBZ'), ('tastier', 'JJR'), ('than', 'IN'), ('chiken', 'NN')]\n",
      "\n",
      "wordnet_tagged ::: [('The', None), ('panner', 'n'), ('is', 'v'), ('tastier', 'a'), ('than', None), ('chiken', 'n')]\n",
      "\n",
      "Original Sentence =>  The panner is tastier than chiken\n",
      "\n",
      "stemmed_sentence =>  the panner is tastier than chiken\n",
      "\n",
      "lemmatized_sentence =>  The panner be tasty than chiken\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'The panner is  tastier than chiken'\n",
    "normalize_sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b6b5950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_tagged:: [('He', 'PRP'), ('quickly', 'RB'), ('finshed', 'VBD'), ('the', 'DT'), ('task', 'NN')]\n",
      "\n",
      "wordnet_tagged ::: [('He', None), ('quickly', 'r'), ('finshed', 'v'), ('the', None), ('task', 'n')]\n",
      "\n",
      "Original Sentence =>  He quickly finshed the task\n",
      "\n",
      "stemmed_sentence =>  he quickli finsh the task\n",
      "\n",
      "lemmatized_sentence =>  He quickly finshed the task\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'He quickly finshed the task'\n",
    "normalize_sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c750fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_tagged:: [('He', 'PRP'), ('is', 'VBZ'), ('quick', 'JJ'), ('.', '.')]\n",
      "\n",
      "wordnet_tagged ::: [('He', None), ('is', 'v'), ('quick', 'a'), ('.', None)]\n",
      "\n",
      "Original Sentence =>  He is quick .\n",
      "\n",
      "stemmed_sentence =>  he is quick .\n",
      "\n",
      "lemmatized_sentence =>  He be quick .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'He is quick.'\n",
    "normalize_sentence(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
